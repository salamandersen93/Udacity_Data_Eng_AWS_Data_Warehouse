Discuss the purpose of this database in context of the startup, Sparkify, and their analytical goals.
State and justify your database schema design and ETL pipeline.
[Optional] Provide example queries and results for song play analysis.

<h1> Udacity Data Engineering Project 3 - Data Warehouse in AWS </h1>

<h2> Introduction </h2>

The basis for this project is a fictional music streaming startup called Sparkify. Due to an expanding user base, the business has a need to migrate their processes and data onto the cloud, with the goal of staging data in Redshift. Their data currently exists in S3, within directories of JSON logs of user activity and song metadata. This project will emaphasize knowledge gained on data warehouses and AWS to build an ETL into redshift.

<h2> Justification of Database Schema and ETL Pipeline Design </h2>

The ETL designed in this project extracts data from the existing S3 storage, stages it in a series of staging tables within Redshift, then executes queries to instatiate analytics tables to host the final data on. The song dataset, hosted within a JSON log, is a subset of the Million Song Dataset and constains metadata about songs and artist. It is comprised of the following fields:
<b>num_songs</b>
<b>artist_id</b>
<b>artist_latitude</b>
<b>artist_longitude</b>
<b>artist_location</b>
<b>artist_name</b>
<b>song_id</b>
<b>title</b>
<b>duration</b>
<b>year</b>

The log dataset contains log files also in a JSON format which is generated by an event simulator using the song dataset. It contains the following fields:
<b>artist</b>
<b>auth</b>
<b>firstName</b>
<b>gender</b>
<b>itemInSession</b>
<b>lastName</b>
<b>length</b>
<b>level</b>
<b>location</b>
<b>method</b>
<b>page</b>
<b>registration</b>
<b>sessionId</b>
<b>song</b>
<b>status</b>
<b>ts</b>
<b>userAgent</b>
<b>userId</b>

In an effort to leverage a schema which can serve data in a format which is favorable for front-end querying/reporting, analysis, and data mining applications, a star schema was selected. The schema proposed in this project uses SongplayTable as a fact table, which contains key quantifiable metrics about individual events (start_time, songplay_id, user_id, level, song_id, artist_id, session_id, location, and user_agent). User_id, song_id, artist_id, and start_time function as foreign keys in the dimension tables. Dimension tables are: user_table, song_table_ artist_table, and time_table. Each of these tables contains the describing parameters for the fact table, and provides context to the event data. For example, the user_table provides additional metadata to contextualize the user identified via user_id in the fact table, such as first name, last name, gender, and level. Representing data in this manner enables easier derivation of business insights, improved query performance, and a straight-forward representation of the data. 


A cluster was launched in Redshift on AWS, then data was loading into staging tables from the original S3 data source. Staging tables were used to allow transformations to the data, including merges and joins. Following this step, data was then ingested into Redshift.
